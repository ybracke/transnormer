{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset sizes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In subword-tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics about the datasets used for training and evaluation.\n",
    "\n",
    "* Dataset size in examples (i.e. paragraphs/sentences)\n",
    "* Statistics on the length of the examples per dataset (mean, outlier boundary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bracke/miniconda3/envs/gpu-venv-transnormer/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from transnormer.preprocess import translit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = {\n",
    "    \"train\" : [\n",
    "        (\"dtaeval\", \"../../data/interim/dtaeval/dtaeval-train.jsonl\"),\n",
    "        (\"ridges\", \"../../data/interim/ridges_bollmann/ridges_bollmann-train.jsonl\"),\n",
    "        (\"deu_news_2020\", \"../../data/interim/deu_news_2020/deu_news_2020-train.jsonl\"),\n",
    "        (\"dtak-1600-1699\", \"../../data/interim/dtak-1600-1699/dtak-1600-1699-train.jsonl\"),\n",
    "        (\"dtak-1700-1799\", \"../../data/interim/dtak-1700-1799/dtak-1700-1799-train.jsonl\"),\n",
    "        (\"dtak-1800-1899\", \"../../data/interim/dtak-1800-1899/dtak-1800-1899-train.jsonl\"),\n",
    "    ],\n",
    "    \"validation\" : [\n",
    "        (\"dtaeval\", \"../../data/interim/dtaeval/dtaeval-validation.jsonl\"),\n",
    "        (\"ridges\", \"../../data/interim/ridges_bollmann/ridges_bollmann-validation.jsonl\"),\n",
    "        (\"deu_news_2020\", \"../../data/interim/deu_news_2020/deu_news_2020-validation.jsonl\"),\n",
    "        (\"dtak-1600-1699\", \"../../data/interim/dtak-1600-1699/dtak-1600-1699-validation.jsonl\"),\n",
    "        (\"dtak-1700-1799\", \"../../data/interim/dtak-1700-1799/dtak-1700-1799-validation.jsonl\"),\n",
    "        (\"dtak-1800-1899\", \"../../data/interim/dtak-1800-1899/dtak-1800-1899-validation.jsonl\"),\n",
    "    ],\n",
    "    \"test\" : [\n",
    "        (\"dtaeval\", \"../../data/interim/dtaeval/dtaeval-test.jsonl\"),\n",
    "        (\"ridges\", \"../../data/interim/ridges_bollmann/ridges_bollmann-test.jsonl\"),\n",
    "        (\"deu_news_2020\", \"../../data/interim/deu_news_2020/deu_news_2020-test.jsonl\"),\n",
    "        (\"dtak-1600-1699\", \"../../data/interim/dtak-1600-1699/dtak-1600-1699-test.jsonl\"),\n",
    "        (\"dtak-1700-1799\", \"../../data/interim/dtak-1700-1799/dtak-1700-1799-test.jsonl\"),\n",
    "        (\"dtak-1800-1899\", \"../../data/interim/dtak-1800-1899/dtak-1800-1899-test.jsonl\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "checkpoint_encoder = \"dbmdz/bert-base-historic-multilingual-cased\"\n",
    "checkpoint_decoder = \"bert-base-multilingual-cased\"\n",
    "\n",
    "# Load tokenizers\n",
    "tokenizer_input = AutoTokenizer.from_pretrained(checkpoint_encoder)\n",
    "tokenizer_output = AutoTokenizer.from_pretrained(checkpoint_decoder)\n",
    "# Replace input tokenizer's normalization component with a custom transliterator\n",
    "transliterator = translit.Transliterator1()\n",
    "tokenizer_input = translit.exchange_transliterator(tokenizer_input, transliterator)\n",
    "\n",
    "def tokenize_input_and_output(batch, tokenizer_input, tokenizer_output):\n",
    "    # Tokenize the inputs and labels\n",
    "    inputs = tokenizer_input(batch[\"orig\"], padding=False, truncation=False)\n",
    "    outputs = tokenizer_output(batch[\"norm\"], padding=False, truncation=False,)\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "    batch[\"labels\"] = outputs.input_ids.copy()\n",
    "    return batch\n",
    "\n",
    "# Compute the token length for each paragraph\n",
    "def get_length(example):\n",
    "    example[\"input_length\"] = len(example[\"input_ids\"])\n",
    "    example[\"output_length\"] = len(example[\"labels\"])\n",
    "    return example\n",
    "\n",
    "def get_upper_outer_fence(lengths):\n",
    "    q3 = np.percentile(lengths, 75)\n",
    "    iqr = q3 - np.percentile(lengths, 25)\n",
    "    upper_outer_fence = q3 + 3*iqr\n",
    "    return upper_outer_fence\n",
    "\n",
    "\n",
    "\n",
    "tokenization_kwargs = {\n",
    "    \"tokenizer_input\": tokenizer_input,\n",
    "    \"tokenizer_output\": tokenizer_output,\n",
    "}\n",
    "\n",
    "df_data = {\n",
    "    \"name\" : [], \"split\" : [], \"examples\" : [], \n",
    "    \"input_len (mean)\" : [], \"output_len (mean)\" : [], \n",
    "    \"input_len (uof)\" : [], \"output_len (uof)\" : []\n",
    "}\n",
    "\n",
    "for split in paths:\n",
    "    for dname, path in paths[split]:\n",
    "        # Load all datasets for this split\n",
    "        ds = datasets.load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "        df_data[\"name\"].append(dname)\n",
    "        df_data[\"split\"].append(split)\n",
    "        df_data[\"examples\"].append(ds.num_rows)\n",
    "        # Tokenize by applying a mapping\n",
    "        ds_tok = ds.map(\n",
    "            tokenize_input_and_output,\n",
    "            fn_kwargs=tokenization_kwargs,\n",
    "            remove_columns=[\"orig\", \"norm\"],\n",
    "            batched=True,\n",
    "            batch_size=64,\n",
    "        )\n",
    "        ds_tok = ds_tok.map(get_length) \n",
    "        df_data[\"input_len (mean)\"].append(np.mean(ds_tok[\"input_length\"]))\n",
    "        df_data[\"output_len (mean)\"].append(np.mean(ds_tok[\"output_length\"]))\n",
    "        df_data[\"input_len (uof)\"].append(get_upper_outer_fence(ds_tok[\"input_length\"]))\n",
    "        df_data[\"output_len (uof)\"].append(get_upper_outer_fence(ds_tok[\"output_length\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = mean; uof = upper outer fence (i.e. 3*IQR above Q3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>split</th>\n",
       "      <th>examples</th>\n",
       "      <th>input_len (mean)</th>\n",
       "      <th>output_len (mean)</th>\n",
       "      <th>input_len (uof)</th>\n",
       "      <th>output_len (uof)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtaeval</td>\n",
       "      <td>train</td>\n",
       "      <td>200524</td>\n",
       "      <td>33.682143</td>\n",
       "      <td>34.116061</td>\n",
       "      <td>141.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ridges</td>\n",
       "      <td>train</td>\n",
       "      <td>2921</td>\n",
       "      <td>30.264635</td>\n",
       "      <td>27.361520</td>\n",
       "      <td>125.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deu_news_2020</td>\n",
       "      <td>train</td>\n",
       "      <td>800000</td>\n",
       "      <td>29.799740</td>\n",
       "      <td>28.026419</td>\n",
       "      <td>92.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dtak-1600-1699</td>\n",
       "      <td>train</td>\n",
       "      <td>754435</td>\n",
       "      <td>41.986521</td>\n",
       "      <td>39.783890</td>\n",
       "      <td>194.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dtak-1700-1799</td>\n",
       "      <td>train</td>\n",
       "      <td>1714657</td>\n",
       "      <td>38.804280</td>\n",
       "      <td>37.652118</td>\n",
       "      <td>165.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dtak-1800-1899</td>\n",
       "      <td>train</td>\n",
       "      <td>2174712</td>\n",
       "      <td>39.749745</td>\n",
       "      <td>39.734626</td>\n",
       "      <td>168.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dtaeval</td>\n",
       "      <td>validation</td>\n",
       "      <td>18278</td>\n",
       "      <td>31.566090</td>\n",
       "      <td>32.407649</td>\n",
       "      <td>126.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ridges</td>\n",
       "      <td>validation</td>\n",
       "      <td>671</td>\n",
       "      <td>30.385991</td>\n",
       "      <td>27.424739</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deu_news_2020</td>\n",
       "      <td>validation</td>\n",
       "      <td>100000</td>\n",
       "      <td>29.813560</td>\n",
       "      <td>28.043310</td>\n",
       "      <td>92.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dtak-1600-1699</td>\n",
       "      <td>validation</td>\n",
       "      <td>157748</td>\n",
       "      <td>39.111108</td>\n",
       "      <td>37.020190</td>\n",
       "      <td>172.0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dtak-1700-1799</td>\n",
       "      <td>validation</td>\n",
       "      <td>216377</td>\n",
       "      <td>38.562098</td>\n",
       "      <td>37.443573</td>\n",
       "      <td>166.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dtak-1800-1899</td>\n",
       "      <td>validation</td>\n",
       "      <td>301339</td>\n",
       "      <td>38.674271</td>\n",
       "      <td>38.671904</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dtaeval</td>\n",
       "      <td>test</td>\n",
       "      <td>21916</td>\n",
       "      <td>26.693877</td>\n",
       "      <td>26.592353</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ridges</td>\n",
       "      <td>test</td>\n",
       "      <td>671</td>\n",
       "      <td>30.052161</td>\n",
       "      <td>27.265276</td>\n",
       "      <td>128.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>deu_news_2020</td>\n",
       "      <td>test</td>\n",
       "      <td>100000</td>\n",
       "      <td>29.822380</td>\n",
       "      <td>28.036140</td>\n",
       "      <td>92.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dtak-1600-1699</td>\n",
       "      <td>test</td>\n",
       "      <td>97560</td>\n",
       "      <td>44.352645</td>\n",
       "      <td>41.903946</td>\n",
       "      <td>205.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dtak-1700-1799</td>\n",
       "      <td>test</td>\n",
       "      <td>203844</td>\n",
       "      <td>37.519804</td>\n",
       "      <td>36.419757</td>\n",
       "      <td>161.0</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dtak-1800-1899</td>\n",
       "      <td>test</td>\n",
       "      <td>293708</td>\n",
       "      <td>37.039420</td>\n",
       "      <td>36.989898</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name       split  examples  input_len (mean)  output_len (mean)  \\\n",
       "0          dtaeval       train    200524         33.682143          34.116061   \n",
       "1           ridges       train      2921         30.264635          27.361520   \n",
       "2    deu_news_2020       train    800000         29.799740          28.026419   \n",
       "3   dtak-1600-1699       train    754435         41.986521          39.783890   \n",
       "4   dtak-1700-1799       train   1714657         38.804280          37.652118   \n",
       "5   dtak-1800-1899       train   2174712         39.749745          39.734626   \n",
       "6          dtaeval  validation     18278         31.566090          32.407649   \n",
       "7           ridges  validation       671         30.385991          27.424739   \n",
       "8    deu_news_2020  validation    100000         29.813560          28.043310   \n",
       "9   dtak-1600-1699  validation    157748         39.111108          37.020190   \n",
       "10  dtak-1700-1799  validation    216377         38.562098          37.443573   \n",
       "11  dtak-1800-1899  validation    301339         38.674271          38.671904   \n",
       "12         dtaeval        test     21916         26.693877          26.592353   \n",
       "13          ridges        test       671         30.052161          27.265276   \n",
       "14   deu_news_2020        test    100000         29.822380          28.036140   \n",
       "15  dtak-1600-1699        test     97560         44.352645          41.903946   \n",
       "16  dtak-1700-1799        test    203844         37.519804          36.419757   \n",
       "17  dtak-1800-1899        test    293708         37.039420          36.989898   \n",
       "\n",
       "    input_len (uof)  output_len (uof)  \n",
       "0             141.0             145.0  \n",
       "1             125.0             108.0  \n",
       "2              92.0              83.0  \n",
       "3             194.0             185.0  \n",
       "4             165.0             161.0  \n",
       "5             168.0             168.0  \n",
       "6             126.0             130.0  \n",
       "7             121.0             112.0  \n",
       "8              92.0              87.0  \n",
       "9             172.0             163.0  \n",
       "10            166.0             158.0  \n",
       "11            160.0             160.0  \n",
       "12            111.0             111.0  \n",
       "13            128.0             115.0  \n",
       "14             92.0              83.0  \n",
       "15            205.0             193.0  \n",
       "16            161.0             157.0  \n",
       "17            155.0             155.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=df_data)\n",
    "print(\"m = mean; uof = upper outer fence (i.e. 3*IQR above Q3)\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more datasets to existing stats file\n",
    "\n",
    "df_new_datasets = df # TODO: compute df with cell above, change paths there\n",
    "df_previously = pd.read_csv('./dataset-sizes.tsv', delimiter='\\t')\n",
    "df_added = pd.concat([df_previously, df_new_datasets],ignore_index=True)\n",
    "\n",
    "df_added\n",
    "\n",
    "df_added.to_csv(\"./dataset-sizes-new.tsv\", sep=\"\\t\")\n",
    "# TODO : check dataset-sizes-new.tsv and rename it to dataset-sizes.tsv\n",
    "#        if everything is alright"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = {\n",
    "    \"train\" : [\n",
    "        (\"dtaeval\", \"../../data/interim/dtaeval/dtaeval-train.jsonl\"),\n",
    "        # (\"ridges\", \"../../data/interim/ridges_bollmann/ridges_bollmann-train.jsonl\"),\n",
    "        # (\"deu_news_2020\", \"../../data/interim/deu_news_2020/deu_news_2020-train.jsonl\"),\n",
    "        # (\"dtak-1600-1699\", \"../../data/interim/dtak-1600-1699/dtak-1600-1699-train.jsonl\"),\n",
    "        # (\"dtak-1700-1799\", \"../../data/interim/dtak-1700-1799/dtak-1700-1799-train.jsonl\"),\n",
    "        # (\"dtak-1800-1899\", \"../../data/interim/dtak-1800-1899/dtak-1800-1899-train.jsonl\"),\n",
    "    ],\n",
    "    \"validation\" : [\n",
    "        (\"dtaeval\", \"../../data/interim/dtaeval/dtaeval-validation.jsonl\"),\n",
    "        # (\"ridges\", \"../../data/interim/ridges_bollmann/ridges_bollmann-validation.jsonl\"),\n",
    "        # (\"deu_news_2020\", \"../../data/interim/deu_news_2020/deu_news_2020-validation.jsonl\"),\n",
    "        # (\"dtak-1600-1699\", \"../../data/interim/dtak-1600-1699/dtak-1600-1699-validation.jsonl\"),\n",
    "        # (\"dtak-1700-1799\", \"../../data/interim/dtak-1700-1799/dtak-1700-1799-validation.jsonl\"),\n",
    "        # (\"dtak-1800-1899\", \"../../data/interim/dtak-1800-1899/dtak-1800-1899-validation.jsonl\"),\n",
    "    ],\n",
    "    \"test\" : [\n",
    "        (\"dtaeval\", \"../../data/interim/dtaeval/dtaeval-test.jsonl\"),\n",
    "        # (\"ridges\", \"../../data/interim/ridges_bollmann/ridges_bollmann-test.jsonl\"),\n",
    "        # (\"deu_news_2020\", \"../../data/interim/deu_news_2020/deu_news_2020-test.jsonl\"),\n",
    "        # (\"dtak-1600-1699\", \"../../data/interim/dtak-1600-1699/dtak-1600-1699-test.jsonl\"),\n",
    "        # (\"dtak-1700-1799\", \"../../data/interim/dtak-1700-1799/dtak-1700-1799-test.jsonl\"),\n",
    "        # (\"dtak-1800-1899\", \"../../data/interim/dtak-1800-1899/dtak-1800-1899-test.jsonl\"),\n",
    "    ]\n",
    "}\n",
    "\n",
    "def utf8len(s):\n",
    "    return len(s.encode('utf-8'))\n",
    "\n",
    "# Compute the token length for each paragraph\n",
    "def get_length(example):\n",
    "    example[\"input_length\"] = utf8len(example[\"orig\"])\n",
    "    example[\"output_length\"] = utf8len(example[\"norm\"])\n",
    "    return example\n",
    "\n",
    "def get_upper_outer_fence(lengths):\n",
    "    q3 = np.percentile(lengths, 75)\n",
    "    iqr = q3 - np.percentile(lengths, 25)\n",
    "    upper_outer_fence = q3 + 3*iqr\n",
    "    return upper_outer_fence\n",
    "\n",
    "\n",
    "df_data = {\n",
    "    \"name\" : [], \"split\" : [], \"examples\" : [], \n",
    "    \"input_len (mean)\" : [], \"output_len (mean)\" : [], \n",
    "    \"input_len (uof)\" : [], \"output_len (uof)\" : []\n",
    "}\n",
    "\n",
    "for split in paths:\n",
    "    for dname, path in paths[split]:\n",
    "        # Load all datasets for this split\n",
    "        ds = datasets.load_dataset(\"json\", data_files=path, split=\"train\")\n",
    "        df_data[\"name\"].append(dname)\n",
    "        df_data[\"split\"].append(split)\n",
    "        df_data[\"examples\"].append(ds.num_rows)\n",
    "        # Tokenize by applying a mapping\n",
    "        ds_tok = ds.map(get_length) \n",
    "        df_data[\"input_len (mean)\"].append(np.mean(ds_tok[\"input_length\"]))\n",
    "        df_data[\"output_len (mean)\"].append(np.mean(ds_tok[\"output_length\"]))\n",
    "        df_data[\"input_len (uof)\"].append(get_upper_outer_fence(ds_tok[\"input_length\"]))\n",
    "        df_data[\"output_len (uof)\"].append(get_upper_outer_fence(ds_tok[\"output_length\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = mean; uof = upper outer fence (i.e. 3*IQR above Q3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>split</th>\n",
       "      <th>examples</th>\n",
       "      <th>input_len (mean)</th>\n",
       "      <th>output_len (mean)</th>\n",
       "      <th>input_len (uof)</th>\n",
       "      <th>output_len (uof)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtaeval</td>\n",
       "      <td>train</td>\n",
       "      <td>200524</td>\n",
       "      <td>127.380952</td>\n",
       "      <td>123.001975</td>\n",
       "      <td>578.0</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dtaeval</td>\n",
       "      <td>validation</td>\n",
       "      <td>18278</td>\n",
       "      <td>121.044972</td>\n",
       "      <td>116.952621</td>\n",
       "      <td>533.0</td>\n",
       "      <td>519.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dtaeval</td>\n",
       "      <td>test</td>\n",
       "      <td>21916</td>\n",
       "      <td>97.155959</td>\n",
       "      <td>93.110787</td>\n",
       "      <td>439.0</td>\n",
       "      <td>422.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name       split  examples  input_len (mean)  output_len (mean)  \\\n",
       "0  dtaeval       train    200524        127.380952         123.001975   \n",
       "1  dtaeval  validation     18278        121.044972         116.952621   \n",
       "2  dtaeval        test     21916         97.155959          93.110787   \n",
       "\n",
       "   input_len (uof)  output_len (uof)  \n",
       "0            578.0             560.0  \n",
       "1            533.0             519.0  \n",
       "2            439.0             422.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=df_data)\n",
    "print(\"m = mean; uof = upper outer fence (i.e. 3*IQR above Q3)\")\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-venv-transnormer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78c4187baaf57098bb0b3703ce789bfcb46625a5d8666ee97b80d797f8c6f211"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
